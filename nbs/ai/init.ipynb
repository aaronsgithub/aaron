{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp ai.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "import sys,gc,traceback\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from pathlib import Path\n",
    "from operator import attrgetter,itemgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "from torch import tensor,nn,optim\n",
    "from torch.utils.data import DataLoader,default_collate\n",
    "from torch.nn import init\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from datasets import load_dataset,load_dataset_builder\n",
    "\n",
    "from aaron.ai.datasets import *\n",
    "from aaron.ai.conv import *\n",
    "from aaron.ai.learner import *\n",
    "from aaron.ai.activations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def clean_ipython_hist():\n",
    "    # Code in this function mainly copied from IPython source\n",
    "    get_ipython = globals().get(\"get_ipython\", None)\n",
    "    if get_ipython is None or not callable(get_ipython): return None\n",
    "    ip = get_ipython() # pylint: disable\n",
    "    user_ns = ip.user_ns\n",
    "    ip.displayhook.flush()\n",
    "    pc = ip.displayhook.prompt_count + 1\n",
    "    for n in range(1, pc): user_ns.pop('_i'+repr(n),None)\n",
    "    user_ns.update(dict(_i='',_ii='',_iii=''))\n",
    "    hm = ip.history_manager\n",
    "    hm.input_hist_parsed[:] = [''] * pc\n",
    "    hm.input_hist_raw[:] = [''] * pc\n",
    "    hm._i = hm._ii = hm._iii = hm._i00 =  ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def clean_tb():\n",
    "    # h/t Piotr Czapla\n",
    "    if hasattr(sys, 'last_traceback'):\n",
    "        traceback.clear_frames(sys.last_traceback)\n",
    "        delattr(sys, 'last_traceback')\n",
    "    if hasattr(sys, 'last_type'): delattr(sys, 'last_type')\n",
    "    if hasattr(sys, 'last_value'): delattr(sys, 'last_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def clean_mem():\n",
    "    clean_tb()\n",
    "    clean_ipython_hist()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BatchTransformCB(Callback):\n",
    "    def __init__(self, tfm, on_train=True, on_val=True): fc.store_attr()\n",
    "\n",
    "    def before_batch(self, learn):\n",
    "        if (self.on_train and learn.training) or (self.on_val and not learn.training):\n",
    "            learn.batch = self.tfm(learn.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GeneralRelu(nn.Module):\n",
    "    def __init__(self, leak=None, sub=None, maxv=None):\n",
    "        super().__init__()\n",
    "        self.leak,self.sub,self.maxv = leak,sub,maxv\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = F.leaky_relu(x,self.leak) if self.leak is not None else F.relu(x)\n",
    "        if self.sub is not None: x -= self.sub\n",
    "        if self.maxv is not None: x.clamp_max_(self.maxv)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_func(f, start=-5., end=5., steps=100):\n",
    "    x = torch.linspace(start, end, steps)\n",
    "    plt.plot(x, f(x))\n",
    "    plt.grid(True, which='both', ls='--')\n",
    "    plt.axhline(y=0, color='k', linewidth=0.7)\n",
    "    plt.axvline(x=0, color='k', linewidth=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def init_weights(m, leaky=0.):\n",
    "    if isinstance(m, (nn.Conv1d,nn.Conv2d,nn.Conv3d)): init.kaiming_normal_(m.weight, a=leaky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _lsuv_stats(hook, mod, inp, outp):\n",
    "    acts = to_cpu(outp)\n",
    "    hook.mean = acts.mean()\n",
    "    hook.std = acts.std()\n",
    "\n",
    "def lsuv_init(model, m, m_in, xb):\n",
    "    h = Hook(m, _lsuv_stats)\n",
    "    with torch.no_grad():\n",
    "        while model(xb) is not None and (abs(h.std-1)>1e-3 or abs(h.mean)>1e-3):\n",
    "            m_in.bias -= h.mean\n",
    "            m_in.weight.data /= h.std\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def conv(ni, nf, ks=3, stride=2, act=nn.ReLU, norm=None, bias=None):\n",
    "    if bias is None: bias = not isinstance(norm, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d))\n",
    "    layers = [nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2, bias=bias)]\n",
    "    if norm: layers.append(norm(nf))\n",
    "    if act: layers.append(act())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_model(act=nn.ReLU, nfs=None, norm=None):\n",
    "    if nfs is None: nfs = [1,8,16,32,64]\n",
    "    layers = [conv(nfs[i], nfs[i+1], act=act, norm=norm) for i in range(len(nfs)-1)]\n",
    "    return nn.Sequential(*layers, conv(nfs[-1],10, act=None, norm=False, bias=True),\n",
    "                         nn.Flatten()).to(def_device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
